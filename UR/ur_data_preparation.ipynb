{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark import SparkContext, SQLContext\n",
    "sc = pyspark.SparkContext()\n",
    "sqlc = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import functions as F, Window\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ActionsData:\n",
    "    \n",
    "    def __init__(self,folder,file,file_repos,user,date,item):\n",
    "        self._data=None\n",
    "        self._data_items=None\n",
    "        self.load_data(folder,file,user,date,item)\n",
    "        self.load_items(folder,file_repos)\n",
    "            \n",
    "    def load_data(self,foldername,filename,user,date,item):\n",
    "        \"\"\"load interactions data of users with repositories\"\"\"\n",
    "        file=os.path.join(foldername+filename)\n",
    "        data=sqlc.read.json(file)\n",
    "        data=data.select(col(user).alias('user_id'),col(date).alias('created_at'), col(item).alias('repo_id'))\n",
    "        self._data=data\n",
    "        \n",
    "    def load_items(self,foldername,filename):\n",
    "        \"\"\"load informations about repositories\"\"\"\n",
    "        file_repos=os.path.join(foldername+filename)\n",
    "        data_repos=sqlc.read.json(file_repos)\n",
    "        self._data_items=data_repos.select(col('id').alias('repo_id'),'name','language').distinct()\n",
    "    \n",
    "    def join_w_repos(self):\n",
    "        \"\"\"consider only interactions to repositories contained in self._data_items\"\"\"\n",
    "        self._data=self._data.join(self._data_items,'repo_id','inner')\n",
    "    \n",
    "    \n",
    "    def remove_duplicates(self):\n",
    "        \"\"\"remove duplicated of interactions of a user with the same repository\"\"\"\n",
    "        self._data=self._data.sort('user_id','created_at',ascending=True).dropDuplicates(['user_id','repo_id'])\n",
    "\n",
    "    def filter_actions(self,min_actions,max_actions):\n",
    "        \"\"\"filter out users inactive users (users who interacted with less than min_actions\n",
    "        repositories) and outliers (users who interacted with more than max_actions repositories)\"\"\"\n",
    "        data_with_max=self._data.groupby('user_id').agg(F.count('repo_id').alias('total_actions'))\n",
    "        data_filter=data_with_max.filter((data_with_max.total_actions>min_actions)\\\n",
    "                                           & (data_with_max.total_actions<max_actions))\n",
    "        \n",
    "        self._data=self._data.join(data_filter.select('user_id'),'user_id','inner')\n",
    "\n",
    "        \n",
    "    def add_rating(self,rating):\n",
    "        \"\"\"add a column with rating value: in a class instance each interaction has the same value\"\"\"\n",
    "        self._data=self._data.groupby('user_id','created_at','repo_id')\\\n",
    "                            .agg((F.count('*')*rating).alias('rating'))\n",
    "        \n",
    "        \n",
    "    def transform(self,min_actions,max_actions,rating):\n",
    "        \"\"\"apply data transformations\"\"\"\n",
    "        self.join_w_repos()\n",
    "        self.remove_duplicates()\n",
    "        self.filter_actions(min_actions,max_actions)\n",
    "        self.add_rating(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleRecommender:\n",
    "    \n",
    "    def __init__(self,data):\n",
    "        \n",
    "        self._data=data\n",
    "        self._train=None\n",
    "        self._test=None\n",
    "        self._model=None\n",
    "        self._predictions_train=None\n",
    "        self._predictions_test=None\n",
    "    \n",
    "    \n",
    "    def message(self,x):\n",
    "        print(x)\n",
    "        \n",
    "    def split_train_test(self):\n",
    "        self._train=self._data.filter('number_of_actions<total_actions')\n",
    "        self._test=self._data.filter('number_of_actions=total_actions')\n",
    "         \n",
    "    def fit(self,param):\n",
    "        self.split_train_test()\n",
    "        als = ALS(maxIter=param['iter'],rank=param['rank'],regParam=param['reg'],userCol=\"user_idn\",\\\n",
    "                    itemCol=\"repo_idn\",ratingCol=\"rating\", seed=1, coldStartStrategy='drop')\n",
    "        evaluator_reg=RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",predictionCol=\"prediction\")      \n",
    "        model=als.fit(self._train)\n",
    "        self._model=model\n",
    "        self._predictions_train=model.transform(self._train)\n",
    "        train_rmse=evaluator_reg.evaluate(self._predictions_train)\n",
    "        self.message('Train RMSE=' + str(train_rmse))\n",
    "        self._predictions_test=model.transform(self._test)\n",
    "        test_rmse=evaluator_reg.evaluate(self._predictions_test)\n",
    "        self.message('Test RMSE=' + str(test_rmse))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample forks data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load forks data: consider only users who forked between 5 and 2500 repositories. Each fork has rating value=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forks=ActionsData(folder='./data/',file='projects_forked_2017.json',\\\n",
    "                  file_repos='projects_not_forked_2017.json',\\\n",
    "                  user='owner_id',date='created_at',item='forked_from')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forks.transform(min_actions=5, max_actions=2500,rating=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forks_data=forks._data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28280"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forks_data.select('user_id').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take sample of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forks_by_item=forks_data.groupby('repo_id').agg(F.count('*').alias('number_of_forks'))\n",
    "forks_by_item=forks_by_item.sort('number_of_forks',ascending=False).limit(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forks_sample=forks_data.join(forks_by_item,'repo_id','inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[repo_id: string, user_id: string, created_at: string, rating: bigint, number_of_forks: bigint]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forks_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forks_sample=forks_sample.select('user_id','repo_id','created_at','rating').withColumn('event',lit('fork'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: string, repo_id: string, created_at: string, rating: bigint, event: string]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forks_sample.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16437"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forks_sample.select('user_id').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new column (total_forks) as the total number of forks by user. This will be used to split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_forks=(Window.partitionBy('user_id').orderBy('created_at').rowsBetween(Window.unboundedPreceding, Window.currentRow))\n",
    "forks_only_sample=forks_sample.withColumn('number_of_actions',F.count('user_id').over(w_forks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_forks=forks_only_sample.groupby('user_id').agg(F.max('number_of_actions').alias('total_forks'))\n",
    "forks_only_sample=forks_only_sample.join(total_forks,'user_id','inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take users with at least 10 forks and save train and test data for evaluation with UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forks_only_sample=forks_only_sample.filter('total_forks>=10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_forks=forks_only_sample.filter('number_of_actions<total_forks')\n",
    "test_forks=forks_only_sample.filter('number_of_actions=total_forks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2185"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_forks.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: string, repo_id: string, created_at: string, rating: bigint, event: string, number_of_actions: bigint, total_forks: bigint]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_forks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_forks.coalesce(1).write.format('csv').mode('overwrite').save('/data/forks_sample_train.csv')\n",
    "test_forks.coalesce(1).write.format('csv').mode('overwrite').save('/data/forks_sample_test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load stars data: consider only users who forked between 20 and 7000 repositories. Each fork has rating value=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stars=ActionsData(folder='./data/',file='watchers_2017.json',\\\n",
    "                  file_repos='projects_not_forked_2017.json',\\\n",
    "                  user='w_user_id',date='w_created_at',item='w_repo_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stars.transform(min_actions=20, max_actions=7000,rating=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stars_data=stars._data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take sample of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stars_by_item=stars_data.groupby('repo_id').agg(F.count('*').alias('number_of_stars'))\n",
    "stars_by_item=stars_by_item.sort('number_of_stars',ascending=False).limit(700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stars_sample=stars_data.join(stars_by_item,'repo_id','inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stars_sample=stars_sample.select('user_id','repo_id','created_at','rating').withColumn('event',lit('star'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: string, repo_id: string, created_at: string, rating: bigint, event: string]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stars_sample.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the union data of forks and stars and drop duplicates (users that forked and starred the same repository)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: string, repo_id: string, created_at: string, rating: bigint, event: string]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union=forks_sample.union(stars_sample)\n",
    "union_dd=union.sort('user_id','created_at').dropDuplicates(['user_id','repo_id'])\n",
    "union_dd.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new column (total_actions) as the total number of interactions (forks or stars) by user. This will be used to split the data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w=(Window.partitionBy('user_id').orderBy('created_at').rowsBetween(Window.unboundedPreceding, Window.currentRow))\n",
    "union_dd=union_dd.withColumn('number_of_actions',F.count('user_id').over(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_actions=union_dd.groupby('user_id').agg(F.max('number_of_actions').alias('total_actions'))\n",
    "union_dd=union_dd.join(total_actions,'user_id','inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create numeric IDs for users and repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexer_user=StringIndexer(inputCol=\"user_id\",outputCol=\"user_idn\")#.setHandleInvalid('skip')\n",
    "indexer_repo=StringIndexer(inputCol='repo_id',outputCol='repo_idn')\n",
    "union_dd=indexer_user.fit(union_dd).transform(union_dd)\n",
    "union_dd=indexer_repo.fit(union_dd).transform(union_dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------------------+------+-----+-----------------+-------------+--------+--------+\n",
      "|user_id| repo_id|          created_at|rating|event|number_of_actions|total_actions|user_idn|repo_idn|\n",
      "+-------+--------+--------------------+------+-----+-----------------+-------------+--------+--------+\n",
      "|2041471|57211856|2017-02-15 21:46:...|     1| star|                1|           15| 15972.0|   156.0|\n",
      "|2041471|57724745|2017-02-21 04:40:...|     1| star|                2|           15| 15972.0|   528.0|\n",
      "|2041471|57090153|2017-03-02 02:34:...|     1| star|                3|           15| 15972.0|    78.0|\n",
      "|2041471|59138123|2017-03-09 21:33:...|     1| star|                4|           15| 15972.0|     2.0|\n",
      "|2041471|60377505|2017-03-28 05:26:...|     1| star|                5|           15| 15972.0|    16.0|\n",
      "|2041471|61091932|2017-04-01 00:21:...|     1| star|                6|           15| 15972.0|    54.0|\n",
      "|2041471|59514446|2017-04-15 04:36:...|     1| star|                7|           15| 15972.0|    96.0|\n",
      "|2041471|62834709|2017-04-27 18:29:...|     1| star|                8|           15| 15972.0|   428.0|\n",
      "|2041471|64411431|2017-05-09 20:36:...|     1| star|                9|           15| 15972.0|   121.0|\n",
      "|2041471|63476539|2017-05-13 02:21:...|     1| star|               10|           15| 15972.0|    59.0|\n",
      "|2041471|56696238|2017-05-21 02:13:...|     1| star|               11|           15| 15972.0|   282.0|\n",
      "|2041471|58875795|2017-06-07 00:16:...|     1| star|               12|           15| 15972.0|     1.0|\n",
      "|2041471|66964575|2017-06-12 19:02:...|     1| star|               13|           15| 15972.0|    15.0|\n",
      "|2041471|64947357|2017-06-20 17:36:...|     1| star|               14|           15| 15972.0|   264.0|\n",
      "|2041471|70709938|2017-07-30 04:51:...|     1| star|               15|           15| 15972.0|   207.0|\n",
      "+-------+--------+--------------------+------+-----+-----------------+-------------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "union_dd.filter('user_idn=15972').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "748606"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union_dd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take only users with at least 10 actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "union_dd=union_dd.filter('total_actions>=10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "652596"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union_dd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24225"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union_dd.select('user_id').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "union_dd.write.format('json').mode('overwrite').save('/data/forks_stars_sample.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model with SimpleRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rec=SimpleRecommender(union_dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE=0.0985648382645678\n",
      "Test RMSE=0.10027968290201808\n"
     ]
    }
   ],
   "source": [
    "parameters={'rank':10,'iter':10,'reg':0.1}\n",
    "rec.fit(param=parameters)\n",
    "\n",
    "model_final=rec._model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model and train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_final.save('/data/als_sample_r10_i10_reg01_fs.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=rec._train\n",
    "test=rec._test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.coalesce(1).write.format('csv').mode('overwrite').save('/data/forks_stars_sample_train.csv')\n",
    "test.coalesce(1).write.format('csv').mode('overwrite').save('/data/forks_stars_sample_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
